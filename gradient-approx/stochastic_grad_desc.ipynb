{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "%pylab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ds(M: int, k1: float, k2: float, b: float, batch_size=10) -> tuple:\n",
    "    X = torch.rand(M, 2) * 100\n",
    "    Y = k1 * X[:,0] + k2 * X[:,1] + b + torch.randn(M)\n",
    "    X_batches = torch.stack(torch.split(X, batch_size))\n",
    "    Y_batches = torch.stack(torch.split(X, batch_size))\n",
    "    return X_batches, Y_batches, (k1, k2, b)\n",
    "\n",
    "def shuffle_batches(X: torch.Tensor, Y: torch.Tensor) -> tuple:\n",
    "    X = X[torch.randperm(X.shape[0])].view(X.shape)\n",
    "    Y = Y[torch.randperm(Y.shape[0])].view(Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "def clip_grad(grad: torch.Tensor, max_grad_len: float) -> tuple:\n",
    "    grad_len = torch.norm(grad)\n",
    "    if grad_len < max_grad_len:\n",
    "        return grad, grad_len\n",
    "    return (grad / grad_len) * max_grad_len, grad_len\n",
    "\n",
    "def approx_k1k2b(k1: float, k2: float, b: float, M: int, epochs=1, alpha=.01, step=1, max_grad_len=1.) -> tuple:\n",
    "    X_batches, Y_batches, _ = gen_ds(M, k1, k2, b)\n",
    "    k1k2b = torch.tensor([1., 1., 0.], dtype=torch.float, requires_grad=True)\n",
    "    for epoch in range(epochs):\n",
    "        X_batches, Y_batches = shuffle_batches(X_batches, Y_batches)\n",
    "        for x_batch, y_batch in zip(X_batches, Y_batches):\n",
    "            yy = k1k2b[0] * x_batch[:,0] + k1k2b[1] * x_batch[:,1] + k1k2b[2]\n",
    "            print(yy)\n",
    "            print('\\n\\n\\n', y_batch)\n",
    "            mse = ((yy - y_batch)**2).mean()\n",
    "            mse.backward()\n",
    "            clipped_grad, _ = clip_grad(k1k2b.grad, max_grad_len)\n",
    "            k1k2kb = torch.tensor(k1k2b - clipped_grad * alpha * step)\n",
    "    return k1k2b[0].item(), k1k2b[1].item(), k1k2b[2].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([149.5231, 140.8339, 112.9755,  96.2219, 112.2466,  85.6545, 125.3837,\n",
      "         60.0117, 145.3310, 115.5002], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "\n",
      " tensor([[42.8536, 95.1193],\n",
      "        [81.1504, 21.5509],\n",
      "        [24.2941, 56.3623],\n",
      "        [ 5.1458, 81.7853],\n",
      "        [35.2678, 20.4255],\n",
      "        [69.5537, 86.3680],\n",
      "        [ 7.0211, 66.8708],\n",
      "        [79.9507, 98.4815],\n",
      "        [12.5995, 48.7345],\n",
      "        [62.4040,  1.9800]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-293-81708967f4f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mapprox_k1k2b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-292-a61317e4f5aa>\u001b[0m in \u001b[0;36mapprox_k1k2b\u001b[0;34m(k1, k2, b, M, epochs, alpha, step, max_grad_len)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myy\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mmse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mclipped_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk1k2b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "approx_k1k2b(1., 2., 3., 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
